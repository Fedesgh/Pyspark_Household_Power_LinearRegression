{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MiApp\") \\\n",
    "    .master(\"local[*]\") \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read.option(\"header\",\"true\").csv(\"house.csv\" , inferSchema=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+---+----------+-------------------+-------------------+---------------------+-------+----------------+--------------+--------------+--------------+\n",
      "|_c0|      Date|               Time|Global_active_power|Global_reactive_power|Voltage|Global_intensity|Sub_metering_1|Sub_metering_2|Sub_metering_3|\n",
      "+---+----------+-------------------+-------------------+---------------------+-------+----------------+--------------+--------------+--------------+\n",
      "|  0|16/12/2006|2024-10-09 17:24:00|              4.216|                0.418|234.840|          18.400|         0.000|         1.000|          17.0|\n",
      "|  1|16/12/2006|2024-10-09 17:25:00|              5.360|                0.436|233.630|          23.000|         0.000|         1.000|          16.0|\n",
      "|  2|16/12/2006|2024-10-09 17:26:00|              5.374|                0.498|233.290|          23.000|         0.000|         2.000|          17.0|\n",
      "+---+----------+-------------------+-------------------+---------------------+-------+----------------+--------------+--------------+--------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.na.drop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Time: timestamp (nullable = true)\n",
      " |-- Global_active_power: string (nullable = true)\n",
      " |-- Global_reactive_power: string (nullable = true)\n",
      " |-- Voltage: string (nullable = true)\n",
      " |-- Global_intensity: string (nullable = true)\n",
      " |-- Sub_metering_1: string (nullable = true)\n",
      " |-- Sub_metering_2: string (nullable = true)\n",
      " |-- Sub_metering_3: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- _c0: integer (nullable = true)\n",
      " |-- Date: string (nullable = true)\n",
      " |-- Time: timestamp (nullable = true)\n",
      " |-- Sub_metering_3: double (nullable = true)\n",
      " |-- Global_active_power_doub: double (nullable = true)\n",
      " |-- Global_reactive_power_doub: double (nullable = true)\n",
      " |-- Voltage_doub: double (nullable = true)\n",
      " |-- Global_intensity_doub: double (nullable = true)\n",
      " |-- Sub_metering_1_doub: double (nullable = true)\n",
      " |-- Sub_metering_2_doub: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Convert columns type to double\n",
    "\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import DoubleType\n",
    "\n",
    "columns_to_doub= [\"Global_active_power\", \"Global_reactive_power\",\"Voltage\",\"Global_intensity\",\"Sub_metering_1\",\"Sub_metering_2\"]\n",
    "\n",
    "for column in columns_to_doub:\n",
    "          \n",
    "        df=df.withColumn(column + \"_doub\" , F.col(column).cast(DoubleType()))\n",
    "\n",
    "df=df.drop(*columns_to_doub)\n",
    "\n",
    "df.printSchema()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CORRELATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.feature import VectorAssembler\n",
    "\n",
    "selected_features = [\"Global_active_power_doub\", \"Global_reactive_power_doub\",\"Voltage_doub\",\"Global_intensity_doub\",\"Sub_metering_1_doub\",\"Sub_metering_2_doub\",\"Sub_metering_3\"]\n",
    "\n",
    "\n",
    "assembler = VectorAssembler(inputCols=selected_features, outputCol=\"features\")\n",
    "df_vectorized = assembler.transform(df.select(selected_features)).select(\"features\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.ml.stat import Correlation\n",
    "\n",
    "pearsonCorr = Correlation.corr(df_vectorized, 'features', 'pearson').collect()[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  0.24701705, -0.39976161,  0.9988886 ,  0.48440128,\n",
       "         0.43456872,  0.63855542],\n",
       "       [ 0.24701705,  1.        , -0.11224557,  0.26612039,  0.12311057,\n",
       "         0.13923089,  0.08961653],\n",
       "       [-0.39976161, -0.11224557,  1.        , -0.41136307, -0.19597555,\n",
       "        -0.16740476, -0.26817208],\n",
       "       [ 0.9988886 ,  0.26612039, -0.41136307,  1.        ,  0.48929822,\n",
       "         0.44034654,  0.62654275],\n",
       "       [ 0.48440128,  0.12311057, -0.19597555,  0.48929822,  1.        ,\n",
       "         0.05472086,  0.10257107],\n",
       "       [ 0.43456872,  0.13923089, -0.16740476,  0.44034654,  0.05472086,\n",
       "         1.        ,  0.08087205],\n",
       "       [ 0.63855542,  0.08961653, -0.26817208,  0.62654275,  0.10257107,\n",
       "         0.08087205,  1.        ]])"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pearsonCorr.toArray()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "independent_var=[\"Global_active_power_doub\", \"Global_reactive_power_doub\",\"Global_intensity_doub\",\"Sub_metering_1_doub\",\"Sub_metering_2_doub\",\"Sub_metering_3\"]\n",
    "\n",
    "dependent_var= \"Voltage_doub\"\n",
    "\n",
    "featureasembler=VectorAssembler(inputCols=independent_var , outputCol=\"independent\")\n",
    "\n",
    "output=featureasembler.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = output.select(\"independent\" , \"Voltage_doub\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DenseVector([21.2816, 3.6219, -5.3393, 0.0105, 0.0173, -0.0497])"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.ml.regression import LinearRegression \n",
    "\n",
    "train_data, test_data = final_df.randomSplit([0.75 , 0.25])\n",
    "\n",
    "regressor= LinearRegression(featuresCol=\"independent\" , labelCol=\"Voltage_doub\" , maxIter=10)\n",
    "regressor = regressor.fit(train_data)\n",
    "\n",
    "regressor.coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|summary|      Voltage_doub|        prediction|\n",
      "+-------+------------------+------------------+\n",
      "|  count|            511770|            511770|\n",
      "|   mean|240.83951890497553|240.84040841507687|\n",
      "| stddev|3.2441211136411416|1.6182189562357407|\n",
      "|    min|            223.99|219.70258211909382|\n",
      "|    max|            253.61|243.30580325415545|\n",
      "+-------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#Prediction statistics\n",
    "\n",
    "pred_results = regressor.evaluate(test_data)\n",
    "pred_results.predictions.describe().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 : 0.24950607839807137\n",
      "Mean absolute error:  2.125165132884811\n",
      "Mean squared error : 7.89842410628906\n"
     ]
    }
   ],
   "source": [
    "# Metrics\n",
    "\n",
    "print(\"R2 :\" , pred_results.r2)\n",
    "print(\"Mean absolute error: \" , pred_results.meanAbsoluteError ) \n",
    "print(\"Mean squared error :\" , pred_results.meanSquaredError)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
